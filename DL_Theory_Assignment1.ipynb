{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcGCuvhB4E52VVrjLlpAYd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sathyakaarthi/Bootcamp-assignments-2022-2023/blob/DL-Theory/DL_Theory_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is the function of a summation junction of a neuron? What is threshold activation function?**\n",
        "\n",
        "*Ans:*\n",
        "\n",
        "A summation junction of a neuron is the point where the electrical signals from other neurons combine and are processed by the neuron. Threshold activation function is the point at which the combined electrical signals reach an intensity where the neuron will fire an action potential."
      ],
      "metadata": {
        "id": "LeqxOApQAhez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What is a step function? What is the difference of step function with threshold function?**\n",
        "\n",
        "*Ans:*\n",
        "\n",
        "* A step function is a type of mathematical function where a certain output is produced when the input value reaches a certain threshold.\n",
        "\n",
        "* The difference between a step function and a threshold function is that a step function has a clear cut-off point, while a threshold function has a gradual increase or decrease in output."
      ],
      "metadata": {
        "id": "Vpj57blXAwBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Explain the McCulloch-Pitts model of neuron.**\n",
        "\n",
        "*Ans:*\n",
        "\n",
        "The main elements of the McCulloch-Pitts model can be summarized as follow:\n",
        "\n",
        "* Neuron activation is binary. A neuron either fire or not-fire.\n",
        "* For a neuron to fire, the weighted sum of inputs has to be equal or larger than a predefined threshold.\n",
        "* If one or more inputs are inhibitory the neuron will not fire.\n",
        "* It takes a fixed one time step for the signal to pass through a link\n",
        "Neither the structure nor the weights change over time.\n"
      ],
      "metadata": {
        "id": "Ues484PtBBcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Explain the ADALINE network model.**\n",
        "\n",
        "*Ans:*\n",
        "\n",
        "ADALINE (Adaptive Linear Neuron or later Adaptive Linear Element) is an early single-layer artificial neural network and the name of the physical device that implemented this network. The network uses memistors. It was developed by professor Bernard Widrow and his doctoral student Ted Hoff at Stanford University in 1960. It is based on the perceptron. It consists of a weight, a bias and a summation function."
      ],
      "metadata": {
        "id": "jznQe9ivBo62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What is the constraint of a simple perceptron? Why it may fail with a real-world data set?**\n",
        "\n",
        "*Ans:*\n",
        "\n",
        "The constraint of a simple perceptron is that it can only learn linear separable functions. It may fail with a real-world data set because the data may not be linearly separable. For example, if the data points have a non-linear relationship, the simple perceptron will not be able to draw the decision boundary correctly."
      ],
      "metadata": {
        "id": "baWXwzqfB-Xf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What is linearly inseparable problem? What is the role of the hidden layer?**\n",
        "\n",
        "*Ans:*\n",
        "\n",
        "* Clearly not all decision problems are linearly separable: they cannot be solved using a linear decision boundary. Problems like these are termed linearly inseparable. XOR is a linearly inseparable problem.\n",
        "\n",
        "* In neural networks, a hidden layer is located between the input and output of the algorithm, in which the function applies weights to the inputs and directs them through an activation function as the output."
      ],
      "metadata": {
        "id": "YtKANa6eCJJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Explain XOR problem in case of a simple perceptron.**\n",
        "\n",
        "*Ans:*\n",
        "\n",
        "A \"single-layer\" perceptron can't implement XOR. The reason is because the classes in XOR are not linearly separable. You cannot draw a straight line to separate the points (0,0),(1,1) from the points (0,1),(1,0).\n",
        "\n",
        "The XOR problem is a problem where a single perceptron cannot accurately classify the data into two distinct classes. XOR stands for Exclusive OR, meaning that if either A or B is true, then the result is true and if both A and B are true or false, then the result is false. The XOR problem occurs when we try to classify data that is not linearly separable. In other words, the data cannot be separated into two distinct classes with a straight line or hyperplane. A single perceptron cannot solve this problem because it is limited to linear classification."
      ],
      "metadata": {
        "id": "FNoME_RjCeiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Design a multi-layer perceptron to implement A XOR B.**\n",
        "\n",
        "*Ans:*\n",
        "\n",
        "The XOR problem with neural networks can be solved by using Multi-Layer Perceptrons or a neural network architecture with an input layer, hidden layer, and output layer. So during the forward propagation through the neural networks, the weights get updated to the corresponding layers and the XOR logic gets executed."
      ],
      "metadata": {
        "id": "5HKWyki7C19c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Explain the single-layer feed forward architecture of ANN.**\n",
        "\n",
        "*Ans:*\n",
        "\n",
        "The input layer is connected to the output layer nodes with weights. All the input nodes are connected to each of the output nodes. The term feed-forward depicts that there is no feedback sent from the output layer to the input layer. This forms a single layer feed-forward network."
      ],
      "metadata": {
        "id": "hRsRBRWODDik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Explain the competitive network architecture of ANN.**\n",
        "\n",
        "*Ans:*\n",
        "\n",
        "* The competitive network architecture of ANN is a type of artificial neural network that uses competition between multiple neurons to determine the output.\n",
        "* This type of network consists of a number of input neurons that feed into a single layer of neurons, which compete to produce the final output.\n",
        "\n",
        "* Each neuron in the output layer has its own set of weights or parameters that it uses to compare the inputs from the previous layer.\n",
        "\n",
        "* The neuron with the highest weighted sum of inputs is the one that produces the output. This type of architecture is used for tasks such as pattern recognition and classification."
      ],
      "metadata": {
        "id": "_UnaLGX5DPjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Consider a multi-layer feed forward neural network. Enumerate and explain steps in the backpropagation algorithm used to train the network.**\n",
        "\n",
        "*Ans:*\n",
        "\n",
        "The backpropagation algorithm used to train a multilayer feed forward neural network involves the following steps:\n",
        "\n",
        "Initialize weights and biases: The weights and biases of the neurons in the network are initialized with small random numbers.\n",
        "\n",
        "**Forward Pass:** The input data is passed through the network. Each neuron in the network performs its calculations and passes the output to the next layer.\n",
        "\n",
        "**Calculate Error: **The error of the output is calculated using a cost or loss function.\n",
        "\n",
        "**Backward Pass:** The error is propagated back through the network. The weights and biases of each neuron are adjusted in order to minimize the error.\n",
        "\n",
        "**Repeat:** Steps 2-4 are repeated until the network converges and the error is minimized"
      ],
      "metadata": {
        "id": "9GnAMXbBD4ff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. What are the advantages and disadvantages of neural networks?**\n",
        "\n",
        "*Ans:*\n",
        "'\n",
        "** Advantages:**\n",
        "\n",
        "* Neural networks are capable of learning complex relationships between inputs and outputs.\n",
        "* Neural networks are robust and can handle noisy and incomplete data.\n",
        "* Neural networks can be used for a variety of tasks such as pattern recognition, classification, and prediction.\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "* Neural networks require a large amount of data for training.\n",
        "* Neural networks can be difficult to interpret and understand.\n",
        "* Neural networks are prone to overfitting."
      ],
      "metadata": {
        "id": "oDeYJHRuERKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Write short notes on any two of the following:**\n",
        "\n",
        "1. Biological neuron\n",
        "\n",
        "2. ReLU function\n",
        "\n",
        "3. Single-layer feed forward ANN\n",
        "\n",
        "4. Gradient descent\n",
        "\n",
        "5. Recurrent networks\n",
        "\n",
        "*Ans:*\n",
        "\n",
        "\n",
        "**Biological neuron:** A biological neuron is a specialized cell found in the nervous system that is capable of transmitting electrical signals. The neuron consists of a cell body, dendrites, and axon which are connected by synapses. The cell body contains the nucleus and other organelles, while the dendrites receive signals from other neurons and transmit them to the cell body. The axon then sends the signal away from the cell body to other neurons.\n",
        "\n",
        "**ReLU function:** ReLU (Rectified Linear Unit) is a type of activation function used in neural networks. It returns 0 for negative values and the same value for positive values, which helps in faster computation. ReLU offers non-linearity to the neural network and provides more flexibility to the model.\n",
        "\n",
        "**Single-layer feed forward ANN:** A single-layer feed forward ANN is a type of artificial neural network (ANN) that consists of one layer of neurons that is connected to the input layer and then to the output layer. Each neuron in the layer is connected to all the neurons in the previous and next layers. The weights of each connection are adjusted during the learning process.\n",
        "\n",
        "**Gradient descent:** Gradient descent is an optimization algorithm used to minimize a function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. It is commonly used for training neural networks and is one of the most popular optimization algorithms. It can also be used to find the local minimum of a function.\n",
        "\n",
        "**Recurrent networks:** Recurrent neural networks are a type of neural networks that are used for processing sequential data. These networks contain cycles that allow information to persist and be passed from one step to the next. They are used in tasks such as speech recognition, language modelling and machine translation."
      ],
      "metadata": {
        "id": "Tl5xSfY2Ev8t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHZ0HravAgZQ"
      },
      "outputs": [],
      "source": []
    }
  ]
}